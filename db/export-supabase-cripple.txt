\
# create_supabase_tables.py
# This script contains the SQL DDL (Data Definition Language) statements
# to recreate the tables defined in cripple.sql for a Supabase project.
#
# How to use:
# 1. Copy the SQL statements for each table.
# 2. Execute them in your Supabase SQL Editor (Project > SQL Editor > New query).
# 3. Alternatively, use a PostgreSQL client connected to your Supabase database.
#
# Note: Supabase automatically handles `id bigint generated by default as identity`
# as primary keys with auto-increment when you define `primary key (id)`.
# The `TABLESPACE pg_default` clause is standard for PostgreSQL and generally
# does not need to be modified for Supabase unless you have specific tablespace requirements.

# SQL statement to create the 'ai_analysis' table
# Stores results from AI-based analysis, potentially linked to documents.
CREATE_AI_ANALYSIS_TABLE_SQL = """
CREATE TABLE public.ai_analysis (
  id bigint generated by default as identity not null,
  name text null,
  created_at timestamp with time zone not null default now(),
  doc_id bigint null,
  score bigint null,
  constraint Agent_pkey primary key (id),
  constraint ai_analysis_doc_id_fkey foreign KEY (doc_id) references public.docs (id)
);
"""

# SQL statement to create the 'community_analysis' table
# Stores results from community-based analysis, potentially linked to documents.
CREATE_COMMUNITY_ANALYSIS_TABLE_SQL = """
CREATE TABLE public.community_analysis (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  doc_id bigint null,
  score bigint null,
  constraint community_pkey primary key (id),
  constraint community_analysis_doc_id_fkey foreign KEY (doc_id) references public.docs (id)
);
"""

# SQL statement to create the 'docs' table
# Stores information about documents, like their path.
CREATE_DOCS_TABLE_SQL = """
CREATE TABLE public.docs (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  path text null,
  constraint docs_pkey primary key (id)
);
"""

# SQL statement to create the 'news' table
# Stores news articles with their content, publication dates, source, and target.
CREATE_NEWS_TABLE_SQL = """
CREATE TABLE public.news (
  id bigint generated by default as identity not null,
  created_at text not null, -- Consider changing to timestamp with time zone
  title text null,
  content text null,
  date_pub text null,    -- Consider changing to date or timestamp
  date_upd text null,    -- Consider changing to date or timestamp
  source_id bigint null,
  target_id bigint null,
  constraint News_pkey primary key (id),
  constraint news_source_id_fkey foreign KEY (source_id) references public.source (id),
  constraint news_target_id_fkey foreign KEY (target_id) references public.target (id)
);
"""

# SQL statement to create the 'news_analysis' table
# Acts as a central table linking news articles to various analyses (AI, community, source, target).
CREATE_NEWS_ANALYSIS_TABLE_SQL = """
CREATE TABLE public.news_analysis (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  is_fake boolean null,
  is_live boolean null,
  score bigint null,
  source_analysis_id bigint null,
  target_analysis_id bigint null,
  ai_analysis_id bigint null,
  community_analysis_id bigint null,
  news_id bigint null,
  constraint news_analysis_pkey primary key (id),
  constraint news_analysis_ai_analysis_id_fkey foreign KEY (ai_analysis_id) references public.ai_analysis (id),
  constraint news_analysis_community_analysis_fkey foreign KEY (community_analysis_id) references public.community_analysis (id),
  constraint news_analysis_news_id_fkey foreign KEY (news_id) references public.news (id),
  constraint news_analysis_source_analysis_id_fkey foreign KEY (source_analysis_id) references public.source_analysis (id),
  constraint news_analysis_target_analysis_fkey foreign KEY (target_analysis_id) references public.target_analysis (id)
);
"""

# SQL statement to create the 'source' table
# Stores information about news sources (e.g., websites, organizations).
CREATE_SOURCE_TABLE_SQL = """
CREATE TABLE public.source (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  name text null,
  url text null,
  constraint source_pkey primary key (id)
);
"""

# SQL statement to create the 'source_analysis' table
# Stores analysis results related to news sources, potentially linked to documents and specific sources.
CREATE_SOURCE_ANALYSIS_TABLE_SQL = """
CREATE TABLE public.source_analysis (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  doc bigint null, -- Assuming this refers to doc_id from 'docs' table. Consider renaming for clarity if so (e.g., doc_id)
  score bigint null,
  source_id bigint null,
  constraint source_analysis_pkey primary key (id),
  constraint source_analysis_doc_fkey foreign KEY (doc) references public.docs (id), -- Changed 'doc' to 'public.docs(id)' for clarity
  constraint source_analysis_source_id_fkey foreign KEY (source_id) references public.source (id)
);
"""

# SQL statement to create the 'target' table
# Stores information about targets mentioned in news (e.g., individuals, companies, cryptocurrencies).
CREATE_TARGET_TABLE_SQL = """
CREATE TABLE public.target (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  name text null,
  url text null,
  constraint target_pkey primary key (id)
);
"""

# SQL statement to create the 'target_analysis' table
# Stores analysis results related to targets, linked to documents and specific targets.
CREATE_TARGET_ANALYSIS_TABLE_SQL = """
CREATE TABLE public.target_analysis (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  doc_id bigint null,
  score real null,
  target_id bigint null,
  constraint target_analysis_pkey primary key (id),
  constraint target_analysis_doc_id_fkey foreign KEY (doc_id) references public.docs (id),
  constraint target_analysis_target_id_fkey foreign KEY (target_id) references public.target (id)
);
"""

# SQL statement to create the 'xrpl_scores' table
# Stores scores and metadata related to XRPL (XRP Ledger) transactions, potentially linked to news articles.
CREATE_XRPL_SCORES_TABLE_SQL = """
CREATE TABLE public.xrpl_scores (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  tx_hash text null,
  step text null,
  score text null, -- Consider numeric type if score is always a number
  ledger_index bigint null,
  news_id bigint null,
  tx_type text null,
  memo_data text null,
  meta jsonb null,
  constraint xrpl_notes_pkey primary key (id), -- Consider renaming constraint to xrpl_scores_pkey for consistency
  constraint xrpl_scores_news_id_fkey foreign KEY (news_id) references public.news (id)
);
"""

# Example of how you might print these SQL statements or prepare them for execution.
# For actual execution, you would use a database connector library like psycopg2
# or run these directly in the Supabase SQL editor.

if __name__ == "__main__":
    print("--- SQL DDL Statements for Supabase Tables ---")

    # Important: Execute these in an order that respects foreign key dependencies.
    # For example, 'docs', 'source', 'target' should be created before tables that reference them.
    # The order below should generally work.

    print("\\n-- Table: docs")
    print(CREATE_DOCS_TABLE_SQL)

    print("\\n-- Table: source")
    print(CREATE_SOURCE_TABLE_SQL)

    print("\\n-- Table: target")
    print(CREATE_TARGET_TABLE_SQL)

    print("\\n-- Table: ai_analysis (depends on docs)")
    print(CREATE_AI_ANALYSIS_TABLE_SQL)

    print("\\n-- Table: community_analysis (depends on docs)")
    print(CREATE_COMMUNITY_ANALYSIS_TABLE_SQL)

    print("\\n-- Table: news (depends on source, target)")
    print(CREATE_NEWS_TABLE_SQL)
    
    print("\\n-- Table: source_analysis (depends on docs, source)")
    print(CREATE_SOURCE_ANALYSIS_TABLE_SQL)

    print("\\n-- Table: target_analysis (depends on docs, target)")
    print(CREATE_TARGET_ANALYSIS_TABLE_SQL)

    # 'news_analysis' depends on 'ai_analysis', 'community_analysis', 'news', 'source_analysis', 'target_analysis'
    # Ensure all its dependencies are created first.
    print("\\n-- Table: news_analysis")
    print(CREATE_NEWS_ANALYSIS_TABLE_SQL)

    print("\\n-- Table: xrpl_scores (depends on news)")
    print(CREATE_XRPL_SCORES_TABLE_SQL)

    print("\\n--- End of SQL DDL Statements ---")
    print("\\nTo create these tables, copy and paste the respective SQL blocks into your Supabase SQL Editor.")
    print("Ensure you create tables with dependencies (foreign keys) after their referenced tables.")
    print("For example, 'docs' must exist before 'ai_analysis'. The order in this script's __main__ block is a suggested execution order.")

    # Example (pseudo-code) for executing with a hypothetical db_execute function:
    #
    # def db_execute(sql_statement):
    #     # Placeholder for your database execution logic
    #     # e.g., using psycopg2:
    #     # conn = psycopg2.connect(your_supabase_connection_string)
    #     # cur = conn.cursor()
    #     # cur.execute(sql_statement)
    #     # conn.commit()
    #     # cur.close()
    #     # conn.close()
    #     print(f"Executing: {sql_statement[:100]}...") # Print snippet
    #
    # if False: # Set to True to simulate execution calls
    #     db_execute(CREATE_DOCS_TABLE_SQL)
    #     db_execute(CREATE_SOURCE_TABLE_SQL)
    #     db_execute(CREATE_TARGET_TABLE_SQL)
    #     db_execute(CREATE_AI_ANALYSIS_TABLE_SQL)
    #     db_execute(CREATE_COMMUNITY_ANALYSIS_TABLE_SQL)
    #     db_execute(CREATE_NEWS_TABLE_SQL)
    #     db_execute(CREATE_SOURCE_ANALYSIS_TABLE_SQL)
    #     db_execute(CREATE_TARGET_ANALYSIS_TABLE_SQL)
    #     db_execute(CREATE_NEWS_ANALYSIS_TABLE_SQL)
    #     db_execute(CREATE_XRPL_SCORES_TABLE_SQL)

